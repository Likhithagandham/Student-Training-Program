{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCOF8Y5K6VPbXCzy4ykQv/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Likhithagandham/Student-Training-Program/blob/main/Credit_Card_Fraud_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Credit Card Fraud Detection\n",
        "\n",
        "This project demonstrates different strategies to detect fraudulent credit card transactions using machine learning.  \n",
        "Since fraud datasets are highly imbalanced, the project compares two main approaches:\n",
        "\n",
        "1. **Class-weighted models** – models are trained with built-in class balancing.  \n",
        "2. **Random undersampling** – the majority class (non-fraud) is reduced to match the minority class (fraud).\n",
        "\n",
        "## Features\n",
        "- Dataset: Synthetic dataset (`synthetic_creditcard.csv`) with imbalanced classes.\n",
        "- Models used:\n",
        "  - Logistic Regression\n",
        "  - Random Forest\n",
        "  - XGBoost\n",
        "- Evaluation metrics:\n",
        "  - ROC-AUC\n",
        "  - Confusion Matrix\n",
        "  - Classification Report (precision, recall, F1-score)\n",
        "\n",
        "## Workflow\n",
        "1. Upload dataset (`synthetic_creditcard.csv`) in Colab.\n",
        "2. Preprocess data and split into train/test sets.\n",
        "3. Train models with:\n",
        "   - **Strategy A:** Class weights\n",
        "   - **Strategy B:** Random undersampling\n",
        "4. Compare results to see which approach works better.\n",
        "\n",
        "## How to Run\n",
        "1. Open the notebook in Google Colab.\n",
        "2. Upload your dataset (CSV).\n",
        "3. Run all cells to train models and view results.\n",
        "\n",
        "## Example Results\n",
        "- Strategy A (class weights) performs well when the imbalance is extreme.\n",
        "- Strategy B (undersampling) provides more balanced recall but may lose overall accuracy.\n",
        "\n",
        "## Future Improvements\n",
        "- Try SMOTE/ADASYN oversampling if dataset size allows.\n",
        "- Add ROC curve plots for better visual comparison.\n",
        "- Experiment with deep learning models (e.g., simple neural networks).\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "_bLZf87Hf9Cu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q imbalanced-learn xgboost\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, confusion_matrix, classification_report, precision_recall_curve, roc_curve, auc, f1_score\n",
        "\n",
        "# upload file\n",
        "uploaded = files.upload()\n",
        "filename = list(uploaded.keys())[0]\n",
        "df = pd.read_csv(filename)\n",
        "print(\"shape:\", df.shape)\n",
        "print(df['Class'].value_counts())\n",
        "\n",
        "# features & target\n",
        "X = df.drop(columns=['Class'])\n",
        "y = df['Class']\n",
        "\n",
        "# stratified split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# ---------- BalancedRandomForest ----------\n",
        "from imblearn.ensemble import BalancedRandomForestClassifier\n",
        "brf = BalancedRandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
        "brf.fit(X_train, y_train)\n",
        "\n",
        "y_proba_brf = brf.predict_proba(X_test)[:,1]\n",
        "print(\"\\nBalancedRandomForest ROC-AUC:\", round(roc_auc_score(y_test, y_proba_brf),4))\n",
        "print(\"BalancedRandomForest PR-AUC :\", round(average_precision_score(y_test, y_proba_brf),4))\n",
        "\n",
        "# pick threshold by maximizing F1 on validation/test\n",
        "prec, rec, th = precision_recall_curve(y_test, y_proba_brf)\n",
        "f1_scores = 2*prec*rec/(prec+rec+1e-12)\n",
        "best_idx = np.nanargmax(f1_scores)\n",
        "best_thr = th[best_idx] if best_idx < len(th) else 0.5\n",
        "y_pred_thr = (y_proba_brf >= best_thr).astype(int)\n",
        "print(\"BRF best threshold:\", round(best_thr,4), \"F1:\", round(f1_scores[best_idx],4))\n",
        "print(\"Confusion matrix (BRF, tuned):\\n\", confusion_matrix(y_test, y_pred_thr))\n",
        "print(classification_report(y_test, y_pred_thr, digits=4))\n",
        "\n",
        "# ---------- EasyEnsembleClassifier ----------\n",
        "from imblearn.ensemble import EasyEnsembleClassifier\n",
        "eec = EasyEnsembleClassifier(n_estimators=10, random_state=42, n_jobs=-1)\n",
        "eec.fit(X_train, y_train)\n",
        "\n",
        "# EasyEnsemble returns an ensemble that supports predict_proba\n",
        "y_proba_eec = eec.predict_proba(X_test)[:,1]\n",
        "print(\"\\nEasyEnsemble ROC-AUC:\", round(roc_auc_score(y_test, y_proba_eec),4))\n",
        "print(\"EasyEnsemble PR-AUC :\", round(average_precision_score(y_test, y_proba_eec),4))\n",
        "\n",
        "prec2, rec2, th2 = precision_recall_curve(y_test, y_proba_eec)\n",
        "f1_scores2 = 2*prec2*rec2/(prec2+rec2+1e-12)\n",
        "best_idx2 = np.nanargmax(f1_scores2)\n",
        "best_thr2 = th2[best_idx2] if best_idx2 < len(th2) else 0.5\n",
        "y_pred_eec = (y_proba_eec >= best_thr2).astype(int)\n",
        "print(\"EEC best threshold:\", round(best_thr2,4), \"F1:\", round(f1_scores2[best_idx2],4))\n",
        "print(\"Confusion matrix (EEC, tuned):\\n\", confusion_matrix(y_test, y_pred_eec))\n",
        "print(classification_report(y_test, y_pred_eec, digits=4))\n",
        "\n",
        "# ---------- Optional: XGBoost with scale_pos_weight (baseline) ----------\n",
        "from xgboost import XGBClassifier\n",
        "neg = (y_train==0).sum()\n",
        "pos = (y_train==1).sum()\n",
        "scale_pos_weight = max(1, neg/pos)\n",
        "xgb = XGBClassifier(eval_metric='logloss', scale_pos_weight=scale_pos_weight, random_state=42, use_label_encoder=False)\n",
        "xgb.fit(X_train, y_train)\n",
        "y_proba_xgb = xgb.predict_proba(X_test)[:,1]\n",
        "print(\"\\nXGBoost ROC-AUC:\", round(roc_auc_score(y_test, y_proba_xgb),4))\n",
        "print(\"XGBoost PR-AUC :\", round(average_precision_score(y_test, y_proba_xgb),4))\n",
        "\n",
        "# threshold tune XGBoost (same method)\n",
        "prec3, rec3, th3 = precision_recall_curve(y_test, y_proba_xgb)\n",
        "f1_scores3 = 2*prec3*rec3/(prec3+rec3+1e-12)\n",
        "best_idx3 = np.nanargmax(f1_scores3)\n",
        "best_thr3 = th3[best_idx3] if best_idx3 < len(th3) else 0.5\n",
        "y_pred_xgb = (y_proba_xgb >= best_thr3).astype(int)\n",
        "print(\"XGB best threshold:\", round(best_thr3,4), \"F1:\", round(f1_scores3[best_idx3],4))\n",
        "print(\"Confusion matrix (XGB, tuned):\\n\", confusion_matrix(y_test, y_pred_xgb))\n",
        "print(classification_report(y_test, y_pred_xgb, digits=4))\n",
        "\n",
        "# ---------- Plot Precision-Recall curves ----------\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(rec, prec, label=f'BRF (AP={average_precision_score(y_test,y_proba_brf):.3f})')\n",
        "plt.plot(rec2, prec2, label=f'EasyEnsemble (AP={average_precision_score(y_test,y_proba_eec):.3f})')\n",
        "plt.plot(rec3, prec3, label=f'XGBoost (AP={average_precision_score(y_test,y_proba_xgb):.3f})')\n",
        "plt.xlabel('Recall'); plt.ylabel('Precision'); plt.title('Precision-Recall Curve'); plt.legend(); plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# ---------- Quick counts to avoid \"undefined metric\" warning ----------\n",
        "print(\"\\nPred counts (BRF tuned):\", np.bincount(y_pred_thr))\n",
        "print(\"Pred counts (EEC tuned):\", np.bincount(y_pred_eec))\n",
        "print(\"Pred counts (XGB tuned):\", np.bincount(y_pred_xgb))\n"
      ],
      "metadata": {
        "id": "Timh5UDTdaxi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}