{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNDCrukKkyhjQqN0zbb5z9U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Likhithagandham/Student-Training-Program/blob/main/PCA_Image_Compression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Project: Image Compression using PCA\n",
        "\n",
        "Overview This project demonstrates how Principal Component Analysis (PCA) can be used for image compression. Instead of storing every pixel value, PCA identifies the most important directions of variance in the data and reconstructs the image using fewer components. This reduces file size while retaining much of the original image quality.\n",
        "\n",
        "Implementation\n",
        "\n",
        "Built in Google Colab using Python, scikit-learn, and matplotlib.\n",
        "\n",
        "Input: User uploads a color image (high resolution supported).\n",
        "\n",
        "Process:\n",
        "\n",
        "Convert image to grayscale or handle each color channel separately.\n",
        "\n",
        "Apply PCA to reduce dimensionality.\n",
        "\n",
        "Reconstruct the compressed image.\n",
        "\n",
        "Output: Displays the reconstructed image and prints file size comparison (original vs. compressed).\n",
        "\n",
        "Key Learnings\n",
        "\n",
        "PCA is not just for numerical datasets but can be applied to images.\n",
        "\n",
        "Higher number of PCA components → clearer image, larger file size.\n",
        "\n",
        "Lower number of PCA components → blurrier image, smaller file size.\n",
        "\n",
        "There’s a trade-off between image clarity and compression ratio.\n",
        "\n",
        "Resume Value This project highlights practical application of ML concepts in real-world tasks like image storage optimization. It shows understanding of unsupervised learning, dimensionality reduction, and the ability to implement ML models in Python."
      ],
      "metadata": {
        "id": "0fA18kg0mMXH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "import os\n",
        "\n",
        "# Step 1: Upload ONE image\n",
        "uploaded = files.upload()\n",
        "filename = list(uploaded.keys())[0]\n",
        "\n",
        "# Step 2: Load and preprocess (color + resize higher res if needed)\n",
        "img = Image.open(filename).convert(\"RGB\")\n",
        "img = img.resize((256, 256))  # manageable resolution\n",
        "img_array = np.array(img) / 255.0  # normalize (0-1)\n",
        "\n",
        "# Step 3: Choose number of PCA components\n",
        "n_components = int(input(\"Enter number of PCA components to keep (e.g., 50, 100, 200): \"))\n",
        "\n",
        "# Step 4: Apply PCA separately on R, G, B channels\n",
        "reconstructed_channels = []\n",
        "for i in range(3):  # R, G, B\n",
        "    channel = img_array[:, :, i]\n",
        "    X = channel.reshape(channel.shape[0], -1)\n",
        "\n",
        "    pca = PCA(n_components=n_components)\n",
        "    X_pca = pca.fit_transform(X)\n",
        "    X_reconstructed = pca.inverse_transform(X_pca)\n",
        "\n",
        "    reconstructed_channels.append(X_reconstructed)\n",
        "\n",
        "# Step 5: Merge channels back into one image\n",
        "reconstructed_img = np.stack(reconstructed_channels, axis=2)\n",
        "\n",
        "# Step 6: Save original and compressed versions\n",
        "original_path = \"original.png\"\n",
        "compressed_path = f\"compressed_{n_components}.png\"\n",
        "\n",
        "Image.fromarray((img_array * 255).astype(np.uint8)).save(original_path)\n",
        "Image.fromarray((np.clip(reconstructed_img, 0, 1) * 255).astype(np.uint8)).save(compressed_path)\n",
        "\n",
        "# Step 7: Show sizes to prove compression\n",
        "print(\"Original file size:\", os.path.getsize(original_path)/1024, \"KB\")\n",
        "print(f\"Compressed file size ({n_components} comps):\", os.path.getsize(compressed_path)/1024, \"KB\")\n",
        "\n",
        "# Step 8: Show Original vs Compressed\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(img_array)\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Original\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(np.clip(reconstructed_img, 0, 1))\n",
        "plt.axis(\"off\")\n",
        "plt.title(f\"Compressed ({n_components} comps)\")\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "aCf7MVXOFd5x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}